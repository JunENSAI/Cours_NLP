{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01730931",
   "metadata": {},
   "source": [
    "# Syntaxe et Analyse Syntaxique (Parsing)\n",
    "\n",
    "Ce module explore comment les machines comprennent la structure grammaticale des phrases. Nous allons passer de l'identification des mots individuels (PoS) à l'analyse des relations complexes entre eux (Parsing).\n",
    "\n",
    "**Objectifs :**\n",
    "\n",
    "1. **PoS Tagging** : Identifier la nature des mots (Nom, Verbe, etc.).\n",
    "\n",
    "2. **Chunking** : Grouper les mots en syntagmes (Groupe Nominal).\n",
    "\n",
    "3. **Dependency Parsing** : Comprendre les relations (Sujet, Objet).\n",
    "\n",
    "4. **NER** : Identifier les entités réelles (Lieux, Organisations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95426c",
   "metadata": {},
   "source": [
    "## 1. Part of Speech (PoS) Tagging\n",
    "\n",
    "Le PoS est le processus d'attribution d'une catégorie grammaticale à chaque mot.\n",
    "\n",
    "* **Tokenisation** : Division du texte en unités (tokens).\n",
    "\n",
    "* **Tagging** : Attribution de l'étiquette (ex: `NN` pour Nom, `VB` pour Verbe).\n",
    "\n",
    "Nous allons comparer deux bibliothèques populaires : **NLTK** et **SpaCy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6242f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "resultat PoS tagging avec nltk:\n",
      "Every: DT\n",
      "part: NN\n",
      "of: IN\n",
      "our: PRP$\n",
      "speech: NN\n",
      "can: MD\n",
      "be: VB\n",
      "decomposed: VBN\n",
      "by: IN\n",
      "tokens: NNS\n"
     ]
    }
   ],
   "source": [
    "# avec nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "text = \"Every part of our speech can be decomposed by tokens\"\n",
    "words = word_tokenize(text)\n",
    "\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "print(\"\\nresultat PoS tagging avec nltk:\")\n",
    "for word, pos_tag in pos_tags:\n",
    "    print(f\"{word}: {pos_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932ff184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultat PoS tagging avec spacy:\n",
      "Every: DET\n",
      "part: NOUN\n",
      "of: ADP\n",
      "our: PRON\n",
      "speech: NOUN\n",
      "can: AUX\n",
      "be: AUX\n",
      "decomposed: VERB\n",
      "by: ADP\n",
      "tokens: NOUN\n"
     ]
    }
   ],
   "source": [
    "#avec spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"resultat PoS tagging avec spacy:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88df72",
   "metadata": {},
   "source": [
    "*Source code : `pos_tag.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9414f2b",
   "metadata": {},
   "source": [
    "## 2. Chunking (Analyse de surface)\n",
    "\n",
    "Une fois les mots étiquetés, nous pouvons les regrouper en **syntagmes** (chunks). Cela permet d'identifier des blocs de sens, comme un \"Groupe Nominal\" (NP).\n",
    "\n",
    "Dans l'exemple ci-dessous, nous définissons une grammaire pour capturer un déterminant, suivi d'adjectifs, suivi d'un nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15031701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags initiaux : [('If', 'IN'), ('the', 'DT'), ('party', 'NN'), ('was', 'VBD'), ('over', 'RB'), ('and', 'CC'), ('our', 'PRP$'), ('time', 'NN'), ('on', 'IN'), ('Earth', 'NN'), ('was', 'VBD'), ('through', 'IN')]\n",
      "\n",
      "Résultat du Chunking (Arbre sous forme texte) :\n",
      "(S\n",
      "  If/IN\n",
      "  (NP the/DT party/NN)\n",
      "  was/VBD\n",
      "  over/RB\n",
      "  and/CC\n",
      "  our/PRP$\n",
      "  (NP time/NN)\n",
      "  on/IN\n",
      "  (NP Earth/NN)\n",
      "  was/VBD\n",
      "  through/IN)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, RegexpParser\n",
    "\n",
    "text = \"If the party was over and our time on Earth was through\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)\n",
    "\n",
    "print(f\"Tags initiaux : {tags}\\n\")\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "tree = chunk_parser.parse(tags)\n",
    "\n",
    "print(\"Résultat du Chunking (Arbre sous forme texte) :\")\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3772f",
   "metadata": {},
   "source": [
    "*Source code : `chunking.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f2c37",
   "metadata": {},
   "source": [
    "## 3. Analyse de Dépendance (Dependency Parsing)\n",
    "\n",
    "Contrairement au Chunking qui groupe les mots, l'analyse de dépendance relie les mots entre eux pour comprendre \"qui fait quoi\".\n",
    "\n",
    "* **Head** : Le mot principal (ex: le verbe).\n",
    "\n",
    "* **Child** : Le mot qui en dépend (ex: le sujet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a892fdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOT             RELATION     TÊTE (HEAD)    \n",
      "---------------------------------------------\n",
      "Autonomous      amod         cars           \n",
      "cars            nsubj        shift          \n",
      "shift           ROOT         shift          \n",
      "insurance       compound     liability      \n",
      "liability       dobj         shift          \n",
      "toward          prep         shift          \n",
      "manufacturers   pobj         toward         \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Autonomous cars shift insurance liability toward manufacturers\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(f\"{'MOT':<15} {'RELATION':<12} {'TÊTE (HEAD)':<15}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} {token.dep_:<12} {token.head.text:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459c263",
   "metadata": {},
   "source": [
    "*Source code : `dependency_parsing.py`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cd371",
   "metadata": {},
   "source": [
    "## 4. Reconnaissance d'Entités Nommées (NER)\n",
    "\n",
    "Le NER dépasse la grammaire pour toucher au sens. Il identifie et classe des objets du monde réel (Entreprises, Pays, Dates, Montants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4691b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTITÉ               LABEL      EXPLICATION\n",
      "--------------------------------------------------\n",
      "Apple                ORG        Companies, agencies, institutions, etc.\n",
      "U.K.                 GPE        Countries, cities, states\n",
      "$1 billion           MONEY      Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(f\"{'ENTITÉ':<20} {'LABEL':<10} {'EXPLICATION'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<20} {ent.label_:<10} {spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a51b0",
   "metadata": {},
   "source": [
    "*Source code : `ner.py`*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
